# üìù C√≥mo Responde OpenAI ‚Äì Versi√≥n 2 (Baseline simple)

**√öltima actualizaci√≥n:** 2025-11-09  
**Archivo principal:** `api/chat.ts`

> Esta versi√≥n describe el flujo reducido con el que retomamos las pruebas. A partir de aqu√≠ iremos a√±adiendo capas (sem√°ntica, quick responses, etc.) y actualizaremos el doc con cada hito.

---

## 1. Flujo general

1. Validar request (`POST`, message string, entorno configurado).  
2. Cargar prompt activo desde Supabase y procesar variables.  
3. Limitar historial a los dos √∫ltimos mensajes cuando hay seguimiento.  
4. Detectar r√°pidamente si el mensaje pide productos (`detectProductQuery`) y extraer un t√©rmino (`extractSearchTermFromMessage`).  
5. Construir mensajes para OpenAI: system prompt + historial reducido + mensaje del usuario (sin instrucciones extra).  
6. Llamada a OpenAI con `tool_choice: 'auto'` permitiendo que el modelo decida qu√© funci√≥n usar.  
7. Ejecutar la funci√≥n elegida (`search_products`, `get_product_by_sku`, etc.) y enviar el resultado tal cual.  
8. Segunda llamada a OpenAI solo si es necesario (sin contexto enriquecido adicional).  
9. Devolver la respuesta final y guardar analytics b√°sicos.

---

## 2. Reglas del system prompt

- Prompt base definido en Supabase (`system_prompts`).  
- Se mantiene una √∫nica instrucci√≥n extra: *no respondas sobre disponibilidad sin consultar la funci√≥n apropiada*.  
- No se a√±aden bloques extra de instrucciones ni avisos de categor√≠a.

---

## 3. Detecci√≥n m√≠nima

- **`detectProductQuery(message)`**: heur√≠stica con palabras clave (tienes, buscamos, precio, etc.).  
- **`extractSearchTermFromMessage(message)`**: regex simples que devuelven el t√©rmino m√°s probable; si falla, el mensaje limpio completo.  
- Si la heur√≠stica dice ‚Äús√≠, es de productos‚Äù, el t√©rmino de b√∫squeda se adjunta como comentario al mensaje del usuario (`[IMPORTANTE: Busca productos relacionados con "X" usando search_products]`).

> No hay comprensi√≥n sem√°ntica ni detector de categor√≠as en esta versi√≥n.

---

## 4. Functions disponibles

Se exponen las funciones hist√≥ricas (`search_products`, `get_product_by_sku`, `search_products_by_category`, etc.), pero ninguna se fuerza desde backend salvo el recordatorio de usar `search_products` cuando se detecta una query de productos.

---

## 5. Respuesta final

- Si OpenAI devuelve un mensaje directo (sin funci√≥n), se responde tal cual.  
- Si llama a una funci√≥n, ejecutamos la funci√≥n y volvemos a llamarlo con: system + historial limitado + respuesta de la funci√≥n sin adornos.  
- No hay quick responses ni formateo backend; el modelo genera el mensaje final libremente.  
- Analytics guardan: mensaje usuario, respuesta, funci√≥n llamada, productos (si hay) y tiempo de respuesta.

---

## 6. Pr√≥ximos pasos

1. Reintroducir comprensi√≥n sem√°ntica (flag `enableSemanticUnderstanding`).  
2. A√±adir detector de categor√≠as con scoring (flag aparte).  
3. Definir formato estructurado opcional para listados (quick response / structured response).  
4. Crear playbook de pruebas con mensajes representativos.

> Cada paso que activemos debe quedar documentado en esta V2 con fecha y exactamente qu√© hace.
